---
title: "Mashable News - Use Case"
output:
  html_document: default
  pdf_document: default
---

```{r results="hide",  include=FALSE}
library(tidyverse)
library(caret)
library(corrplot)
library(party)
library(gbm)
library(reshape2)
library(caTools)

set.seed(1234)

 
```


# 1. Read datasets
```{r}

 
news_data <- read.csv('Data/dat_train.csv')

str(news_data)
 

```
# 2. Data enginering 
```{r}

news_data$weekday_is_monday <- as.factor(news_data$weekday_is_monday )
news_data$weekday_is_tuesday <- as.factor(news_data$weekday_is_tuesday )
news_data$weekday_is_wednesday <- as.factor(news_data$weekday_is_wednesday )
news_data$weekday_is_thursday <- as.factor(news_data$weekday_is_thursday )
news_data$weekday_is_friday <- as.factor(news_data$weekday_is_friday )
news_data$weekday_is_saturday <- as.factor(news_data$weekday_is_saturday )
news_data$weekday_is_sunday <- as.factor(news_data$weekday_is_sunday )
news_data$is_weekend <- as.factor(news_data$is_weekend )

news_data$popular<-as.factor(ifelse(news_data$shares>1400,"yes","no"))
```


# 3. Visualisation plots 

```{r}
 

ggplot(news_data, aes(as.factor(is_weekend)))+
geom_bar(aes(fill = popular))+
labs(x = "Article posted at the weekend",y = "Number of articles based on popularity")

ggplot(news_data, aes(as.factor(data_channel_is_socmed)))+
geom_bar(aes(fill = popular))+
labs(x = "Social media channel",y = "Number of articles based on popularity")

 


ggplot(news_data, aes(x = news_data$kw_avg_avg)) +
  geom_histogram(aes(color = popular, fill = popular), 
                position = "identity", bins = 500, alpha = 0.4) +
  coord_cartesian(xlim = c(0, 7500), ylim = c(0, 750))+
labs(x = "Avg. keyword (avg. shares)")

 

num<-unlist(lapply(news_data, is.numeric))
news_data_cor<-news_data[,num]
cor.matrix<-cor(news_data_cor)
corrplot(cor.matrix, order="hclust", tl.pos='n')
highcor<-findCorrelation(cor.matrix, cutoff=0.9, exact=TRUE, name=TRUE)

 
#distribution of target variable 
table(news_data$popular)


```


# 4.Test/Train Dataset

```{r , cache= TRUE}
 
## 80% of the sample size
smp_size <- floor(0.80 * nrow(news_data))


train_ind <- sample(seq_len(nrow(news_data)), size = smp_size)

news_train <- news_data[train_ind, ]
news_test <- news_data[-train_ind, ]
```

# 5.Model Creation 
```{r , cache= TRUE,  results="hide"}
myControl <- trainControl(
  method = "cv",
  number = 5,
  verboseIter = FALSE
)
model_gbm <- train(popular ~ kw_avg_avg	+
                      self_reference_min_shares+
                      is_weekend+
                      kw_min_avg+
                      kw_max_avg+
                      kw_max_max	+
                      self_reference_avg_sharess	+
                      data_channel_is_socmed	+
                      n_unique_tokens	 	+
                      kw_avg_max+
                      data_channel_is_entertainment	+
                      LDA_02	+
                      kw_avg_min 	+
                      data_channel_is_tech	+
                      LDA_00	 	+
                      LDA_01	 	+
                      title_sentiment_polarity	+
                      weekday_is_saturday	+
                      LDA_03 +
                      global_subjectivity,
                     data = news_train ,
                     method = "gbm",
                     trControl = myControl
                   )
 



```
# 6.Model Performance 
```{r}

summary(model_gbm)

gbm.pred <- predict(model_gbm, news_test )
gbm.probs <- predict(model_gbm, news_test,type="prob")
gbm.confmat <- confusionMatrix(gbm.pred, news_test$popular, positive = "yes")

gbm.confmat

varImp(model_gbm)
```


